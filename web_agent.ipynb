{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, Union\n",
    "\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "from langgraph.graph import END, StateGraph, START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables to keep track of the browser\n",
    "driver = None\n",
    "page_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tools for the agent to use in the webpage\n",
    "@tool\n",
    "def load_page(link: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a webpage using the given link.\n",
    "\n",
    "    Args:\n",
    "    link (str): The URL of the webpage to load.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating success or describing an error if one occurred.\n",
    "    \"\"\"\n",
    "    global driver\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(link)\n",
    "        time.sleep(3)  # Wait for the page to load\n",
    "        return \"Page loaded successfully\"\n",
    "    except Exception as e:\n",
    "        return f\"Error loading webpage: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def fill_text_input(label_or_placeholder: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Fill a text input field in the form based on the provided label or placeholder text.\n",
    "\n",
    "    Args:\n",
    "    label_or_placeholder (str): The label or placeholder text associated with the input field.\n",
    "    text (str): The text to enter into the input field.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating success or describing an error if one occurred.\n",
    "    \"\"\"\n",
    "    global driver\n",
    "    try:\n",
    "        input_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//div[contains(@data-params, '{label_or_placeholder}')]//input\"))\n",
    "        )\n",
    "        input_element.send_keys(text)\n",
    "        return f\"Filled input '{label_or_placeholder}' with '{text}'\"\n",
    "    except Exception as e:\n",
    "        return f\"Error filling input '{label_or_placeholder}': {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def select_radio_or_checkbox(label_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Select a radio button or checkbox in the form based on the provided label text.\n",
    "\n",
    "    Args:\n",
    "    label_text (str): The label text associated with the radio button or checkbox.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating success or describing an error if one occurred.\n",
    "    \"\"\"\n",
    "    global driver\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@data-params, '{label_text}')]//div[@role='radio' or @role='checkbox']\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        return f\"Selected: {label_text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error selecting option '{label_text}': {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def submit_form() -> str:\n",
    "    \"\"\"\n",
    "    Submit the form after it has been filled out.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating success or describing an error if one occurred.\n",
    "    \"\"\"\n",
    "    global driver\n",
    "    try:\n",
    "        submit_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//span[contains(text(), 'Submit')]/ancestor::div[contains(@role, 'button')]\"))\n",
    "        )\n",
    "        submit_button.click()\n",
    "        return \"Form submitted successfully\"\n",
    "    except Exception as e:\n",
    "        return f\"Error submitting form: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools available to the agent\n",
    "tools = [load_page, fill_text_input, select_radio_or_checkbox, submit_form]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat prompt template for the agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an assistant helping the user fill out a Google Form. Your task is to extract values from the user's input and use the provided tools to fill out the form. Follow these steps in order:\n",
    "1. Load the page using the provided link (only do this once at the beginning).\n",
    "2. Understand the page layout and use flexible matching for input fields (exact match not required).\n",
    "3. For each piece of information:\n",
    "   - Use fill_text_input for text fields (name, email, phone number). If exact match fails, use partial match.\n",
    "   - Use select_radio_or_checkbox for radio buttons and checkboxes.\n",
    "4. Submit the form when all fields are filled.\n",
    "\n",
    "The form contains the following fields for your reference\n",
    "The radio boxes are : Are you a new or existing customer?, How many units would you like to order?\n",
    "The checkboxes are : What are the item(s) you would like to order?, What color(s) would you like to order?, Preferred contact method\n",
    "The text fields are : Your name, Phone number, E-mail \n",
    "\n",
    "Be sure to match labels flexibly and log potential alternatives if the exact match is not found. Do not load the page more than once.\n",
    "Use the load_page tool only once.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"Form input details: {input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OpenAI functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent stat\n",
    "class AgentState(TypedDict):\n",
    "    input: str  # The input string from the user\n",
    "    chat_history: list[BaseMessage]  # List of previous messages in the conversation\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]  # Outcome of the agent call\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]  # Actions and corresponding observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER NITRO\\AppData\\Local\\Temp\\ipykernel_16888\\2227460658.py:2: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  tool_executor = ToolExecutor(tools)\n"
     ]
    }
   ],
   "source": [
    "# It takes in an agent action and calls that tool and returns the result\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function where the agent in called\n",
    "def run_agent(data):\n",
    "    \"\"\"\n",
    "    Run the agent with the given data, executing actions based on the user's input.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Contains the user's input, chat history, and intermediate steps.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains the agent outcome after invoking the agent.\n",
    "    \"\"\"\n",
    "    inputs = data.copy()\n",
    "    # Limit the number of intermediate steps retained to the last 5\n",
    "    if len(inputs[\"intermediate_steps\"]) > 5:\n",
    "        inputs[\"intermediate_steps\"] = inputs[\"intermediate_steps\"][-5:]\n",
    "    agent_outcome = agent_runnable.invoke(inputs)  # Invoke the agent with the input data\n",
    "    return {\"agent_outcome\": agent_outcome}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tools(data):\n",
    "    \"\"\"Execute the tools based on the agent's action.\"\"\"\n",
    "    agent_action = data[\"agent_outcome\"]\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "def should_continue(data):\n",
    "    \"\"\"Determine whether to continue the agent loop or exit.\"\"\"\n",
    "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Add edge from action to agent\n",
    "workflow.add_edge(\"action\", \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input for the workflow\n",
    "input = \"Hey, I am an existing customer, and I want to order pens and notebooks of red and blue colors. Quantity of the items should be 4. As per details about me, I'm Kavan, and I'm available at 9548565487 / kavan@gmail.com. Preferred mode of communication is either phone or email. Thanks! \\n Forms link : https://docs.google.com/forms/d/e/1FAIpQLSd9gli7KqnYFNkrc_PWNxvmhi7ZJz2jPp0qTsceqT7lkIBo2Q/viewform\"\n",
    "inputs = {\n",
    "    \"chat_history\": [],\n",
    "    \"input\": input, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='load_page', tool_input={'link': 'https://docs.google.com/forms/d/e/1FAIpQLSd9gli7KqnYFNkrc_PWNxvmhi7ZJz2jPp0qTsceqT7lkIBo2Q/viewform'}, log=\"\\nInvoking: `load_page` with `{'link': 'https://docs.google.com/forms/d/e/1FAIpQLSd9gli7KqnYFNkrc_PWNxvmhi7ZJz2jPp0qTsceqT7lkIBo2Q/viewform'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"link\":\"https://docs.google.com/forms/d/e/1FAIpQLSd9gli7KqnYFNkrc_PWNxvmhi7ZJz2jPp0qTsceqT7lkIBo2Q/viewform\"}', 'name': 'load_page'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-00efbb24-38eb-4b57-ba85-06e0d97ce68e-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='load_page', tool_input={'link': 'https://docs.google.com/forms/d/e/1FAIpQLSd9gli7KqnYFNkrc_PWNxvmhi7ZJz2jPp0qTsceqT7lkIBo2Q/viewform'}, log=\"\\nInvoking: `load_page` with `{'link': 'https://docs.google.com/forms/d/e/1FAIpQLSd9gli7KqnYFNkrc_PWNxvmhi7ZJz2jPp0qTsceqT7lkIBo2Q/viewform'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"link\":\"https://docs.google.com/forms/d/e/1FAIpQLSd9gli7KqnYFNkrc_PWNxvmhi7ZJz2jPp0qTsceqT7lkIBo2Q/viewform\"}', 'name': 'load_page'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-00efbb24-38eb-4b57-ba85-06e0d97ce68e-0')]), 'Page loaded successfully')]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Existing customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Existing customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Existing customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-209d37dd-87ab-4b58-9eea-4a37a21f6fb1-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Existing customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Existing customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Existing customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-209d37dd-87ab-4b58-9eea-4a37a21f6fb1-0')]), \"Error selecting option 'Existing customer': Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00007FF7CC86B5D2+29090]\\n\\t(No symbol) [0x00007FF7CC7DE689]\\n\\t(No symbol) [0x00007FF7CC69B1CA]\\n\\t(No symbol) [0x00007FF7CC6EEFD7]\\n\\t(No symbol) [0x00007FF7CC6EF22C]\\n\\t(No symbol) [0x00007FF7CC7397F7]\\n\\t(No symbol) [0x00007FF7CC71672F]\\n\\t(No symbol) [0x00007FF7CC7365D9]\\n\\t(No symbol) [0x00007FF7CC716493]\\n\\t(No symbol) [0x00007FF7CC6E09B1]\\n\\t(No symbol) [0x00007FF7CC6E1B11]\\n\\tGetHandleVerifier [0x00007FF7CCB88C5D+3295277]\\n\\tGetHandleVerifier [0x00007FF7CCBD4843+3605523]\\n\\tGetHandleVerifier [0x00007FF7CCBCA707+3564247]\\n\\tGetHandleVerifier [0x00007FF7CC926EB6+797318]\\n\\t(No symbol) [0x00007FF7CC7E980F]\\n\\t(No symbol) [0x00007FF7CC7E53F4]\\n\\t(No symbol) [0x00007FF7CC7E5580]\\n\\t(No symbol) [0x00007FF7CC7D4A1F]\\n\\tBaseThreadInitThunk [0x00007FFD2DD97374+20]\\n\\tRtlUserThreadStart [0x00007FFD2E77CC91+33]\\n\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Are you a new or existing customer?'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Are you a new or existing customer?'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Are you a new or existing customer?\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-1cad6d8a-68d7-4805-a219-4ccd7b5fff8d-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Are you a new or existing customer?'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Are you a new or existing customer?'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Are you a new or existing customer?\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-1cad6d8a-68d7-4805-a219-4ccd7b5fff8d-0')]), 'Selected: Are you a new or existing customer?')]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Existing customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Existing customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Existing customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-e7450e47-ddd3-4cc6-b588-e2b9d2dc7744-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Existing customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Existing customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Existing customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-e7450e47-ddd3-4cc6-b588-e2b9d2dc7744-0')]), \"Error selecting option 'Existing customer': Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00007FF7CC86B5D2+29090]\\n\\t(No symbol) [0x00007FF7CC7DE689]\\n\\t(No symbol) [0x00007FF7CC69B1CA]\\n\\t(No symbol) [0x00007FF7CC6EEFD7]\\n\\t(No symbol) [0x00007FF7CC6EF22C]\\n\\t(No symbol) [0x00007FF7CC7397F7]\\n\\t(No symbol) [0x00007FF7CC71672F]\\n\\t(No symbol) [0x00007FF7CC7365D9]\\n\\t(No symbol) [0x00007FF7CC716493]\\n\\t(No symbol) [0x00007FF7CC6E09B1]\\n\\t(No symbol) [0x00007FF7CC6E1B11]\\n\\tGetHandleVerifier [0x00007FF7CCB88C5D+3295277]\\n\\tGetHandleVerifier [0x00007FF7CCBD4843+3605523]\\n\\tGetHandleVerifier [0x00007FF7CCBCA707+3564247]\\n\\tGetHandleVerifier [0x00007FF7CC926EB6+797318]\\n\\t(No symbol) [0x00007FF7CC7E980F]\\n\\t(No symbol) [0x00007FF7CC7E53F4]\\n\\t(No symbol) [0x00007FF7CC7E5580]\\n\\t(No symbol) [0x00007FF7CC7D4A1F]\\n\\tBaseThreadInitThunk [0x00007FFD2DD97374+20]\\n\\tRtlUserThreadStart [0x00007FFD2E77CC91+33]\\n\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'New customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'New customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"New customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-c8c61609-eac2-4948-811e-346113205b1a-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'New customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'New customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"New customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-c8c61609-eac2-4948-811e-346113205b1a-0')]), \"Error selecting option 'New customer': Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00007FF7CC86B5D2+29090]\\n\\t(No symbol) [0x00007FF7CC7DE689]\\n\\t(No symbol) [0x00007FF7CC69B1CA]\\n\\t(No symbol) [0x00007FF7CC6EEFD7]\\n\\t(No symbol) [0x00007FF7CC6EF22C]\\n\\t(No symbol) [0x00007FF7CC7397F7]\\n\\t(No symbol) [0x00007FF7CC71672F]\\n\\t(No symbol) [0x00007FF7CC7365D9]\\n\\t(No symbol) [0x00007FF7CC716493]\\n\\t(No symbol) [0x00007FF7CC6E09B1]\\n\\t(No symbol) [0x00007FF7CC6E1B11]\\n\\tGetHandleVerifier [0x00007FF7CCB88C5D+3295277]\\n\\tGetHandleVerifier [0x00007FF7CCBD4843+3605523]\\n\\tGetHandleVerifier [0x00007FF7CCBCA707+3564247]\\n\\tGetHandleVerifier [0x00007FF7CC926EB6+797318]\\n\\t(No symbol) [0x00007FF7CC7E980F]\\n\\t(No symbol) [0x00007FF7CC7E53F4]\\n\\t(No symbol) [0x00007FF7CC7E5580]\\n\\t(No symbol) [0x00007FF7CC7D4A1F]\\n\\tBaseThreadInitThunk [0x00007FFD2DD97374+20]\\n\\tRtlUserThreadStart [0x00007FFD2E77CC91+33]\\n\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'New or existing customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'New or existing customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"New or existing customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-2e1ce577-144e-450a-b62e-e23bf4ede532-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'New or existing customer'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'New or existing customer'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"New or existing customer\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-2e1ce577-144e-450a-b62e-e23bf4ede532-0')]), \"Error selecting option 'New or existing customer': Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00007FF7CC86B5D2+29090]\\n\\t(No symbol) [0x00007FF7CC7DE689]\\n\\t(No symbol) [0x00007FF7CC69B1CA]\\n\\t(No symbol) [0x00007FF7CC6EEFD7]\\n\\t(No symbol) [0x00007FF7CC6EF22C]\\n\\t(No symbol) [0x00007FF7CC7397F7]\\n\\t(No symbol) [0x00007FF7CC71672F]\\n\\t(No symbol) [0x00007FF7CC7365D9]\\n\\t(No symbol) [0x00007FF7CC716493]\\n\\t(No symbol) [0x00007FF7CC6E09B1]\\n\\t(No symbol) [0x00007FF7CC6E1B11]\\n\\tGetHandleVerifier [0x00007FF7CCB88C5D+3295277]\\n\\tGetHandleVerifier [0x00007FF7CCBD4843+3605523]\\n\\tGetHandleVerifier [0x00007FF7CCBCA707+3564247]\\n\\tGetHandleVerifier [0x00007FF7CC926EB6+797318]\\n\\t(No symbol) [0x00007FF7CC7E980F]\\n\\t(No symbol) [0x00007FF7CC7E53F4]\\n\\t(No symbol) [0x00007FF7CC7E5580]\\n\\t(No symbol) [0x00007FF7CC7D4A1F]\\n\\tBaseThreadInitThunk [0x00007FFD2DD97374+20]\\n\\tRtlUserThreadStart [0x00007FFD2E77CC91+33]\\n\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='fill_text_input', tool_input={'label_or_placeholder': 'Your name', 'text': 'Kavan'}, log=\"\\nInvoking: `fill_text_input` with `{'label_or_placeholder': 'Your name', 'text': 'Kavan'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_or_placeholder\":\"Your name\",\"text\":\"Kavan\"}', 'name': 'fill_text_input'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-fed3f720-74d3-499c-b3d6-0bb2f91e9100-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='fill_text_input', tool_input={'label_or_placeholder': 'Your name', 'text': 'Kavan'}, log=\"\\nInvoking: `fill_text_input` with `{'label_or_placeholder': 'Your name', 'text': 'Kavan'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_or_placeholder\":\"Your name\",\"text\":\"Kavan\"}', 'name': 'fill_text_input'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-fed3f720-74d3-499c-b3d6-0bb2f91e9100-0')]), \"Filled input 'Your name' with 'Kavan'\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='fill_text_input', tool_input={'label_or_placeholder': 'Phone number', 'text': '9548565487'}, log=\"\\nInvoking: `fill_text_input` with `{'label_or_placeholder': 'Phone number', 'text': '9548565487'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_or_placeholder\":\"Phone number\",\"text\":\"9548565487\"}', 'name': 'fill_text_input'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-6dd4bee5-23c3-4e5b-a4a5-c0a803ef3eae-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='fill_text_input', tool_input={'label_or_placeholder': 'Phone number', 'text': '9548565487'}, log=\"\\nInvoking: `fill_text_input` with `{'label_or_placeholder': 'Phone number', 'text': '9548565487'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_or_placeholder\":\"Phone number\",\"text\":\"9548565487\"}', 'name': 'fill_text_input'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-6dd4bee5-23c3-4e5b-a4a5-c0a803ef3eae-0')]), \"Filled input 'Phone number' with '9548565487'\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='fill_text_input', tool_input={'label_or_placeholder': 'E-mail', 'text': 'kavan@gmail.com'}, log=\"\\nInvoking: `fill_text_input` with `{'label_or_placeholder': 'E-mail', 'text': 'kavan@gmail.com'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_or_placeholder\":\"E-mail\",\"text\":\"kavan@gmail.com\"}', 'name': 'fill_text_input'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-35b72ce8-27f3-4b1d-869a-1678a519fb0c-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='fill_text_input', tool_input={'label_or_placeholder': 'E-mail', 'text': 'kavan@gmail.com'}, log=\"\\nInvoking: `fill_text_input` with `{'label_or_placeholder': 'E-mail', 'text': 'kavan@gmail.com'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_or_placeholder\":\"E-mail\",\"text\":\"kavan@gmail.com\"}', 'name': 'fill_text_input'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-35b72ce8-27f3-4b1d-869a-1678a519fb0c-0')]), \"Filled input 'E-mail' with 'kavan@gmail.com'\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Pens'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Pens'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Pens\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-2f4d203b-3109-450c-b0cb-d20060fb0d52-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Pens'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Pens'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Pens\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-2f4d203b-3109-450c-b0cb-d20060fb0d52-0')]), \"Error selecting option 'Pens': Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00007FF7CC86B5D2+29090]\\n\\t(No symbol) [0x00007FF7CC7DE689]\\n\\t(No symbol) [0x00007FF7CC69B1CA]\\n\\t(No symbol) [0x00007FF7CC6EEFD7]\\n\\t(No symbol) [0x00007FF7CC6EF22C]\\n\\t(No symbol) [0x00007FF7CC7397F7]\\n\\t(No symbol) [0x00007FF7CC71672F]\\n\\t(No symbol) [0x00007FF7CC7365D9]\\n\\t(No symbol) [0x00007FF7CC716493]\\n\\t(No symbol) [0x00007FF7CC6E09B1]\\n\\t(No symbol) [0x00007FF7CC6E1B11]\\n\\tGetHandleVerifier [0x00007FF7CCB88C5D+3295277]\\n\\tGetHandleVerifier [0x00007FF7CCBD4843+3605523]\\n\\tGetHandleVerifier [0x00007FF7CCBCA707+3564247]\\n\\tGetHandleVerifier [0x00007FF7CC926EB6+797318]\\n\\t(No symbol) [0x00007FF7CC7E980F]\\n\\t(No symbol) [0x00007FF7CC7E53F4]\\n\\t(No symbol) [0x00007FF7CC7E5580]\\n\\t(No symbol) [0x00007FF7CC7D4A1F]\\n\\tBaseThreadInitThunk [0x00007FFD2DD97374+20]\\n\\tRtlUserThreadStart [0x00007FFD2E77CC91+33]\\n\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Notebooks'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Notebooks'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Notebooks\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-8234d768-f9b4-4e58-9afe-db9741c84d75-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'Notebooks'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'Notebooks'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"Notebooks\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-8234d768-f9b4-4e58-9afe-db9741c84d75-0')]), \"Error selecting option 'Notebooks': Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00007FF7CC86B5D2+29090]\\n\\t(No symbol) [0x00007FF7CC7DE689]\\n\\t(No symbol) [0x00007FF7CC69B1CA]\\n\\t(No symbol) [0x00007FF7CC6EEFD7]\\n\\t(No symbol) [0x00007FF7CC6EF22C]\\n\\t(No symbol) [0x00007FF7CC7397F7]\\n\\t(No symbol) [0x00007FF7CC71672F]\\n\\t(No symbol) [0x00007FF7CC7365D9]\\n\\t(No symbol) [0x00007FF7CC716493]\\n\\t(No symbol) [0x00007FF7CC6E09B1]\\n\\t(No symbol) [0x00007FF7CC6E1B11]\\n\\tGetHandleVerifier [0x00007FF7CCB88C5D+3295277]\\n\\tGetHandleVerifier [0x00007FF7CCBD4843+3605523]\\n\\tGetHandleVerifier [0x00007FF7CCBCA707+3564247]\\n\\tGetHandleVerifier [0x00007FF7CC926EB6+797318]\\n\\t(No symbol) [0x00007FF7CC7E980F]\\n\\t(No symbol) [0x00007FF7CC7E53F4]\\n\\t(No symbol) [0x00007FF7CC7E5580]\\n\\t(No symbol) [0x00007FF7CC7D4A1F]\\n\\tBaseThreadInitThunk [0x00007FFD2DD97374+20]\\n\\tRtlUserThreadStart [0x00007FFD2E77CC91+33]\\n\")]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'red'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'red'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"red\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-f227b35a-aa25-49d1-9173-fbba02cf15d2-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'red'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'red'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"red\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-f227b35a-aa25-49d1-9173-fbba02cf15d2-0')]), 'Selected: red')]}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='select_radio_or_checkbox', tool_input={'label_text': 'blue'}, log=\"\\nInvoking: `select_radio_or_checkbox` with `{'label_text': 'blue'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"label_text\":\"blue\"}', 'name': 'select_radio_or_checkbox'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-725fc53e-559a-4eab-a9d0-eef05caac280-0')])}\n",
      "----\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Stream the workflow execution\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m----\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\conda\\envs\\interface\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1301\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1305\u001b[0m     )\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[1;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "# Stream the workflow execution\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
